####################
PE UCT C Experiments
####################

-----------------------
PE UCT C experiment
-----------------------

This experiment is to determine a good value of c for the UCT action selection.

Params:
- num episodes = 50
- step limit = 40
- gamma = 0.95


Trial #0 NST l=0 vs random
``````````````````````````

Use R_hi from convergence experiments = 90


Trial #1 random vs random
``````````````````````````
- Agents:
  - 0:
    - Random policy
  - 1:
    - Random policy

+---------------------------------+-----------+-----------+
| AgentID                         |         0 |         1 |
+---------------------------------+-----------+-----------+
| policy_entropy_mean             |    2.0000 |    2.0000 |
| policy_entropy_std              |    0.0000 |    0.0000 |
| search_time_mean                |    0.0000 |    0.0000 |
| search_time_std                 |    0.0000 |    0.0000 |
| update_time_mean                |    0.0000 |    0.0000 |
| update_time_std                 |    0.0000 |    0.0000 |
| reinvigoration_time_mean        |    0.0000 |    0.0000 |
| reinvigoration_time_std         |    0.0000 |    0.0000 |
| num_episodes                    |        50 |        50 |
| episode_returns_mean            |  -63.4200 |   -7.4200 |
| episode_returns_std             |   42.8281 |   56.0115 |
| episode_returns_max             |   61.0000 |   93.0000 |
| episode_returns_min             | -138.0000 | -139.0000 |
| episode_discounted_returns_mean |  -24.1072 |   -6.9312 |
| episode_discounted_returns_std  |   13.8658 |   18.2198 |
| episode_discounted_returns_max  |   -3.5785 |   60.6105 |
| episode_discounted_returns_min  |  -72.0736 |  -29.2810 |
| episode_steps_mean              |   35.7400 |   35.7400 |
| episode_steps_std               |    7.9845 |    7.9845 |
| episode_times_mean              |    0.0074 |    0.0074 |
| episode_times_std               |    0.0016 |    0.0016 |
| episode_dones                   |    0.3200 |    0.3200 |
| num_outcome_LOSS                |        15 |         1 |
| num_outcome_DRAW                |        34 |        34 |
| num_outcome_WIN                 |         1 |        15 |
| num_outcome_NA                  |         0 |         0 |
+---------------------------------+-----------+-----------+

Result
``````

R_lo = lowest return achieved by random rollouts
R_hi = highest return achieved by NST l=0 with uct_c = 0

c = R_hi - R_lo = 90 - (-138) = 228

Round up to 230 to be consistent with Chaser

Validation
``````````

Comparing NST l=0 using uct_c=230 vs uct_c=70 (my handpicked value) vs uct_c=0,
over 10 episodes and using num_sims=2048

Params:
- num episodes = 10
- step limit = 40
- gamma = 0.95
- uct_c = C
- epsilon = 0.1
- seed = 0
- grid_name = '8by8v2'
- Agents:
  - 0:
    - NST l=0
    - Num sims = K
    - rollout_policies:
      - 0:
        - PESPPolicy
        - r_hi: 92
          r_lo: -138
      - 1:
        - None
  - 1:
    - Random

OLD Result withour r_hi, r_lo (except c=0)

UCT C   | return +/- std    | Win/Loss/Draw  | Max   |
--------|--------------------------------------------
0       | 70.10 +/- 60.10   | 9/1/0          | 92    |
70      | 30.30 +/- 75.61   | 6/1/3          | 92    |
230     | -37.60 +/- 47.65  | 1/1/8          | 78    |
------------------------------------------------------

NEWER Result using r_hi=92, r_lo=-138

UCT C   | return +/- std    | Win/Loss/Draw  | Max   |
--------|--------------------------------------------
0       | 70.10 +/- 60.10   | 9/1/0          | 92    |
70      | -9.30 +/- 70.02   | 3/1/6          | 92    |
230     | -3.10 +/- 56.37   | 3/0/7          | 84    |
230     | -24.50 +/- 59.23  | 2/1/7          | 92    | with num_sims=4096
------------------------------------------------------


---------------------------------------------
Runner NST l=0 (POMDP) Convergence experiment
---------------------------------------------

This experiment was to determine how many samples required by an NST l=0 agent
to converge in terms of policy when using c=0

Params:
- num episodes = 20
- step limit = 40
- gamma = 0.95
- uct_c = 0
- epsilon = 0.25
- seed = 0
- grid_name = '8by8v2'
- Agents:
  - 0:
    - NST l=0
    - Num sims = K
    - rollout_policies: None
  - 1:
    - Random

Summary
```````
Num sims    | return +/- std     | Win/Loss/Draw  | Max   |
------------|----------------------------------------------
512         | -6.05 +/- 51.90    | 6/14/0         | 78.0  |
1024        | 0.55 +/- 72.24     | 9/3/8          | 89.0  |
2048        | 5.50 +/- 55.98     | 8/0/12         | 90.0  |
-----------------------------------------------------------

Trial #0 512 sims
`````````````````
+---------------------------------+----------+-----------+
| AgentID                         |        0 |         1 |
+---------------------------------+----------+-----------+
| policy_entropy_mean             |   0.0015 |    2.0000 |
| policy_entropy_std              |   0.0047 |    0.0000 |
| search_time_mean                |   2.0999 |    0.0000 |
| search_time_std                 |   0.6890 |    0.0000 |
| update_time_mean                |   0.0303 |    0.0000 |
| update_time_std                 |   0.0103 |    0.0000 |
| reinvigoration_time_mean        |   0.0008 |    0.0000 |
| reinvigoration_time_std         |   0.0017 |    0.0000 |
| num_episodes                    |       20 |        20 |
| episode_returns_mean            |  -6.0500 |  -66.0500 |
| episode_returns_std             |  51.8994 |   39.8440 |
| episode_returns_max             |  78.0000 |  -40.0000 |
| episode_returns_min             | -40.0000 | -132.0000 |
| episode_discounted_returns_mean |  -8.4993 |  -23.1518 |
| episode_discounted_returns_std  |  12.6712 |   10.2688 |
| episode_discounted_returns_max  |  17.8828 |  -16.5583 |
| episode_discounted_returns_min  | -16.5583 |  -43.5885 |
| episode_steps_mean              |  36.3500 |   36.3500 |
| episode_steps_std               |   5.9353 |    5.9353 |
| episode_times_mean              |  80.9089 |   80.9089 |
| episode_times_std               |  33.6650 |   33.6650 |
| episode_dones                   |   0.3000 |    0.3000 |
| num_outcome_LOSS                |        0 |         6 |
| num_outcome_DRAW                |       14 |        14 |
| num_outcome_WIN                 |        6 |         0 |
| num_outcome_NA                  |        0 |         0 |
+---------------------------------+----------+-----------+

Trial #1 1024 sims
``````````````````
+---------------------------------+-----------+-----------+
| AgentID                         |         0 |         1 |
+---------------------------------+-----------+-----------+
| policy_entropy_mean             |    0.0013 |    2.0000 |
| policy_entropy_std              |    0.0056 |    0.0000 |
| search_time_mean                |    3.6590 |    0.0000 |
| search_time_std                 |    1.5000 |    0.0000 |
| update_time_mean                |    0.0454 |    0.0000 |
| update_time_std                 |    0.0235 |    0.0000 |
| reinvigoration_time_mean        |    0.0011 |    0.0000 |
| reinvigoration_time_std         |    0.0023 |    0.0000 |
| num_episodes                    |        20 |        20 |
| episode_returns_mean            |    0.5500 |  -59.4500 |
| episode_returns_std             |   72.2437 |   72.2852 |
| episode_returns_max             |   89.0000 |   88.0000 |
| episode_returns_min             | -121.0000 | -138.0000 |
| episode_discounted_returns_mean |   -7.3745 |  -20.7074 |
| episode_discounted_returns_std  |   27.2857 |   27.1940 |
| episode_discounted_returns_max  |   45.8432 |   42.6010 |
| episode_discounted_returns_min  |  -60.0674 |  -62.2288 |
| episode_steps_mean              |   30.0500 |   30.0500 |
| episode_steps_std               |   10.6746 |   10.6746 |
| episode_times_mean              |  121.9544 |  121.9544 |
| episode_times_std               |   75.2586 |   75.2586 |
| episode_dones                   |    0.6000 |    0.6000 |
| num_outcome_LOSS                |         3 |         9 |
| num_outcome_DRAW                |         8 |         8 |
| num_outcome_WIN                 |         9 |         3 |
| num_outcome_NA                  |         0 |         0 |
+---------------------------------+-----------+-----------+


Trial #2 2048 sims
``````````````````
+---------------------------------+----------+-----------+
| AgentID                         |        0 |         1 |
+---------------------------------+----------+-----------+
| policy_entropy_mean             |   0.0010 |    2.0000 |
| policy_entropy_std              |   0.0042 |    0.0000 |
| search_time_mean                |   8.5347 |    0.0000 |
| search_time_std                 |   2.8970 |    0.0000 |
| update_time_mean                |   0.0997 |    0.0000 |
| update_time_std                 |   0.0316 |    0.0000 |
| reinvigoration_time_mean        |   0.0025 |    0.0000 |
| reinvigoration_time_std         |   0.0041 |    0.0000 |
| num_episodes                    |       20 |        20 |
| episode_returns_mean            |   5.5000 |  -74.5000 |
| episode_returns_std             |  55.9844 |   42.5940 |
| episode_returns_max             |  90.0000 |  -40.0000 |
| episode_returns_min             | -40.0000 | -136.0000 |
| episode_discounted_returns_mean |  -4.3818 |  -26.3037 |
| episode_discounted_returns_std  |  18.1437 |   13.7813 |
| episode_discounted_returns_max  |  49.2560 |  -16.5583 |
| episode_discounted_returns_min  | -16.5583 |  -64.5040 |
| episode_steps_mean              |  34.9000 |   34.9000 |
| episode_steps_std               |   8.2395 |    8.2395 |
| episode_times_mean              | 321.3025 |  321.3025 |
| episode_times_std               | 147.3608 |  147.3608 |
| episode_dones                   |   0.4000 |    0.4000 |
| num_outcome_LOSS                |        0 |         8 |
| num_outcome_DRAW                |       12 |        12 |
| num_outcome_WIN                 |        8 |         0 |
| num_outcome_NA                  |        0 |         0 |
+---------------------------------+----------+-----------+

Trial #3 4096 sims
``````````````````
exp 2



---------------------------------------------
Runner NST l=0 (POMDP) Convergence experiment
---------------------------------------------

OLD RESULT using PESPPolicy for rollouts

This experiment was to determine how many samples required by an NST l=0 agent
to converge in terms of policy when using c=0

Params:
- num episodes = 50
- step limit = 40
- gamma = 0.95
- uct_c = 0
- epsilon = 0.25
- seed = 0
- grid_name = '8by8v2'
- Agents:
  - 0:
    - NST l=0
    - Num sims = K
    - rollout_policies:
      - 0:
        - PESPPolicy
        - r_hi: None
        - r_lo: None
      - 1:
        - None
  - 1:
    - Random

Summary
```````
Num sims    | return +/- std     | Win/Loss/Draw  | Max   |
------------|----------------------------------------------
512         | 68.66 +/- 60.16    | 45/5/0         | 92.0  |
1024        | 37.86 +/- 83.91    | 37/11/2        | 92.0  |
2048        | 57.08 +/- 70.58    | 42/7/1         | 92.0  |
4096        | 55.32 +/- 71.49    | 41/2/7         | 92.0  |
-----------------------------------------------------------

POSGMCP converges with low number of sims for c=0


Trial #0 512 sims
`````````````````
+---------------------------------+-----------+-----------+
| AgentID                         |         0 |         1 |
+---------------------------------+-----------+-----------+
| policy_entropy_mean             |    0.0086 |    2.0000 |
| policy_entropy_std              |    0.0226 |    0.0000 |
| search_time_mean                |    0.5371 |    0.0000 |
| search_time_std                 |    0.1896 |    0.0000 |
| update_time_mean                |    0.0154 |    0.0000 |
| update_time_std                 |    0.0214 |    0.0000 |
| reinvigoration_time_mean        |    0.0017 |    0.0000 |
| reinvigoration_time_std         |    0.0056 |    0.0000 |
| num_episodes                    |        50 |        50 |
| episode_returns_mean            |   68.6600 |  -91.3400 |
| episode_returns_std             |   60.1633 |   60.2563 |
| episode_returns_max             |   92.0000 |   99.0000 |
| episode_returns_min             | -122.0000 | -130.0000 |
| episode_discounted_returns_mean |   35.0538 |  -51.1947 |
| episode_discounted_returns_std  |   35.6677 |   35.5528 |
| episode_discounted_returns_max  |   56.6299 |   89.3000 |
| episode_discounted_returns_min  |  -91.2000 |  -69.4200 |
| episode_steps_mean              |   12.3400 |   12.3400 |
| episode_steps_std               |    5.0224 |    5.0224 |
| episode_times_mean              |    7.6348 |    7.6348 |
| episode_times_std               |    6.7517 |    6.7517 |
| episode_dones                   |    1.0000 |    1.0000 |
| num_outcome_LOSS                |         5 |        45 |
| num_outcome_DRAW                |         0 |         0 |
| num_outcome_WIN                 |        45 |         5 |
| num_outcome_NA                  |         0 |         0 |
+---------------------------------+-----------+-----------+

Trial #1 1024 sims
``````````````````
+---------------------------------+-----------+-----------+
| AgentID                         |         0 |         1 |
+---------------------------------+-----------+-----------+
| policy_entropy_mean             |    0.0066 |    2.0000 |
| policy_entropy_std              |    0.0173 |    0.0000 |
| search_time_mean                |    1.3183 |    0.0000 |
| search_time_std                 |    0.5699 |    0.0000 |
| update_time_mean                |    0.0306 |    0.0000 |
| update_time_std                 |    0.0243 |    0.0000 |
| reinvigoration_time_mean        |    0.0059 |    0.0000 |
| reinvigoration_time_std         |    0.0109 |    0.0000 |
| num_episodes                    |        50 |        50 |
| episode_returns_mean            |   37.8600 |  -66.1400 |
| episode_returns_std             |   83.9066 |   83.1096 |
| episode_returns_max             |   92.0000 |   98.0000 |
| episode_returns_min             | -132.0000 | -139.0000 |
| episode_discounted_returns_mean |   16.3879 |  -34.4752 |
| episode_discounted_returns_std  |   45.7055 |   45.6801 |
| episode_discounted_returns_max  |   56.6299 |   83.8850 |
| episode_discounted_returns_min  |  -87.5900 |  -69.4200 |
| episode_steps_mean              |   15.1000 |   15.1000 |
| episode_steps_std               |    8.7023 |    8.7023 |
| episode_times_mean              |   24.7437 |   24.7437 |
| episode_times_std               |   28.1524 |   28.1524 |
| episode_dones                   |    0.9600 |    0.9600 |
| num_outcome_LOSS                |        11 |        37 |
| num_outcome_DRAW                |         2 |         2 |
| num_outcome_WIN                 |        37 |        11 |
| num_outcome_NA                  |         0 |         0 |
+---------------------------------+-----------+-----------+

Trial #2 2048 sims
`````````````````
+---------------------------------+-----------+-----------+
| AgentID                         |         0 |         1 |
+---------------------------------+-----------+-----------+
| policy_entropy_mean             |    0.0004 |    2.0000 |
| policy_entropy_std              |    0.0028 |    0.0000 |
| search_time_mean                |    2.4425 |    0.0000 |
| search_time_std                 |    1.0632 |    0.0000 |
| update_time_mean                |    0.0532 |    0.0000 |
| update_time_std                 |    0.0472 |    0.0000 |
| reinvigoration_time_mean        |    0.0032 |    0.0000 |
| reinvigoration_time_std         |    0.0068 |    0.0000 |
| num_episodes                    |        50 |        50 |
| episode_returns_mean            |   57.0800 |  -82.9200 |
| episode_returns_std             |   70.5770 |   69.9965 |
| episode_returns_max             |   92.0000 |   97.0000 |
| episode_returns_min             | -123.0000 | -132.0000 |
| episode_discounted_returns_mean |   26.6946 |  -44.2367 |
| episode_discounted_returns_std  |   39.2479 |   38.9876 |
| episode_discounted_returns_max  |   56.6299 |   78.7407 |
| episode_discounted_returns_min  |  -84.1605 |  -69.4200 |
| episode_steps_mean              |   13.9000 |   13.9000 |
| episode_steps_std               |    6.2650 |    6.2650 |
| episode_times_mean              |   40.8674 |   40.8674 |
| episode_times_std               |   45.1494 |   45.1494 |
| episode_dones                   |    0.9800 |    0.9800 |
| num_outcome_LOSS                |         7 |        42 |
| num_outcome_DRAW                |         1 |         1 |
| num_outcome_WIN                 |        42 |         7 |
| num_outcome_NA                  |         0 |         0 |
+---------------------------------+-----------+-----------+

Trial #3 4096 sims
``````````````````
+---------------------------------+-----------+-----------+
| AgentID                         |         0 |         1 |
+---------------------------------+-----------+-----------+
| policy_entropy_mean             |    0.0002 |    2.0000 |
| policy_entropy_std              |    0.0008 |    0.0000 |
| search_time_mean                |    4.8741 |    0.0000 |
| search_time_std                 |    2.6327 |    0.0000 |
| update_time_mean                |    0.1215 |    0.0000 |
| update_time_std                 |    0.1862 |    0.0000 |
| reinvigoration_time_mean        |    0.0111 |    0.0000 |
| reinvigoration_time_std         |    0.0204 |    0.0000 |
| num_episodes                    |        50 |        50 |
| episode_returns_mean            |   55.3200 |  -80.6800 |
| episode_returns_std             |   71.4945 |   70.4166 |
| episode_returns_max             |   92.0000 |   99.0000 |
| episode_returns_min             | -129.0000 | -127.0000 |
| episode_discounted_returns_mean |   26.4855 |  -43.4055 |
| episode_discounted_returns_std  |   42.1531 |   42.5408 |
| episode_discounted_returns_max  |   56.6299 |   89.3000 |
| episode_discounted_returns_min  |  -91.2000 |  -69.4200 |
| episode_steps_mean              |   13.6400 |   13.6400 |
| episode_steps_std               |    7.5386 |    7.5386 |
| episode_times_mean              |   80.0543 |   80.0543 |
| episode_times_std               |   99.2227 |   99.2227 |
| episode_dones                   |    0.9600 |    0.9600 |
| num_outcome_LOSS                |         7 |        41 |
| num_outcome_DRAW                |         2 |         2 |
| num_outcome_WIN                 |        41 |         7 |
| num_outcome_NA                  |         0 |         0 |
+---------------------------------+-----------+-----------+
